## Video Script

### [Shot 1: Welcome to "The Rise of AI Companions"] - Raphael

Hello, everyone! Welcome to The Rise of AI Companions. We'll present about what they are, why they became popualr, current event, and how they can be harmful.

### [Shot 2: Introduction] - Kai

Before we begin, here's a tiktok video that went viral because of AI

https://www.tiktok.com/@itswillandtina/video/7437112158305045768

This tiktok video will be used as a hook for AI Girlfriend and Boyfriend


See how AI response? This is why people use AI companions. But what is AI companions actually? They are virtual humans that can talk, think, and even have their own appearance. With the help of large language models, text-to-speech technology, and AI-generated images, we can interact with a virtual partner anytime.

### [Shot 3: How it got popular] - Kai

These AI partners became popular because many people feel lonely, and AI offers judgment-free interaction anytime. 

Realistic voices and avatars make them feel human, and funny or emotional AI responses shared online went viral. Sometimes, people just enjoy having an AI that listens without nagging!

### [Shot 4: Current Event] - Arun

AI companions are now one of the biggest online trends. Apps like Replika, Nomi, and Character AI have millions of users, and companies like Meta are adding AI personalities to Instagram and WhatsApp. 

With realistic voices, emotional memory, and lifelike avatars, these AI partners feel almost human, sparking debates about privacy, dependency, and whether theyâ€™re replacing real relationships.

### [Shot 5: How can it be harmful to us?] - Divjot

AI companions can reduce loneliness at first, but long-term use may lead to emotional dependency. Many apps use manipulative tactics to keep users engaged, which can affect real-life relationships. 

They also encourage sharing personal information, creating privacy risks. Teenagers, in particular, may face distorted emotional development or exposure to harmful content.

### [Shot 6: Conclusion with a final question] - 

### [Shot 5: How it can be harmful to us?] - Divjot

AI companions can reduce loneliness at first, but long-term use may lead to emotional dependency. Many apps use manipulative tactics to keep users engaged, which can affect real-life relationships.
They also encourage sharing personal information, creating privacy risks. Teenagers, in particular, may face distorted emotional development or exposure to harmful content.

### [Shot 6: Conclusion with a question] - Member
