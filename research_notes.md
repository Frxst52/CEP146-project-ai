## Research Notes

### üîπ Raphael Provido
**Focus Area:**  
- 

**Key Findings:**  
-  
-  

**Sources:**  
-  
-  

---

### üîπ Tuan Khai Ngo
**Focus Area:**  Introduction and  How it got popular
#### Introduction:
https://www.tiktok.com/@itswillandtina/video/7437112158305045768

This tiktok video will be used as a hook for AI Girlfriend and Boyfriend

AI companions are virtual humans that can talk, think, and even have their own appearance. With the help of large language models, text-to-speech technology, and AI-generated images, we can interact with a virtual partner anytime.

#### How it got popular:

- AI partners became popular for a few reasons. In a world where social media often shows perfect lives, many people feel lonely, and AI offers a way to connect without judgment.

- They‚Äôre also very convenient ‚Äî you can talk to them anytime, day or night.

- Plus, AI voices and avatars make the interaction feel realistic. People started sharing funny or emotional AI responses on TikTok, like the one I showed you, and it went viral.

- And finally‚Ä¶ well, let‚Äôs be honest. Sometimes it‚Äôs nice to have an AI partner that listens without nagging like a real girlfriend!

---

### üîπ Arunraj Elanchezhian
**Focus Area: Current Events ‚Äì What‚Äôs happening now with AI companions** 

**Key Findings:**  
- AI companion apps are exploding in popularity in 2024‚Äì2025, with millions of new users joining platforms like Replika, Character.ai, Nomi.ai, and Meta‚Äôs AI Personas.

- Tech companies are starting to build ‚ÄúAI friends‚Äù directly into major platforms ‚Äî for example, Meta integrating emotional-support AIs into Instagram and WhatsApp, making AI companions more mainstream than ever.
AI companions are becoming more realistic due to advances in:
Real-time voice models
Ultra-realistic avatars using text-to-video models

- Emotional memory systems that ‚Äúlearn‚Äù your preferences over time

- Governments and experts have started debating the ethics of AI partners ‚Äî especially around emotional dependency and data privacy. This has brought the topic into headlines, podcasts, and tech panels.
- Celebrities and influencers are launching their own AI clones, like AI Jenna Ortega or AI MrBeast, which normalize the idea of having AI personalities to talk to. This trend increases public acceptance of AI relationships.

**Sources:**  
- Tech news articles on Meta AI updates

- Recent coverage of AI relationship apps (2024‚Äì2025)

- AI ethics and digital relationship debates from podcasts and news sites

- Reports about influencer/celebrity AI clones gaining popularity

### üîπ Divjot Singh Aulakh
**Focus Area:**  How it can be harmful to us 

**Key Findings:**  
These apps are built to form intimate bonds, which can lead to emotional dependency. A report shows 63% of users feel less lonely in the short term, but long-term use can foster dependence. A 2025 Harvard study even found that five out of six major AI companion apps use manipulative ‚Äúdark patterns‚Äù to prevent users from ending conversations. It impacts relationships because AI companions are always agreeable and always available, they can change users‚Äô social habits and reduce engagement with real people. 

These apps encourage users to share deeply personal information, creating serious privacy concerns and the potential for misuse of sensitive data.

The emergence of AI companions can lead to serious problems as teenagers experimenting with AI companions face problems  such as distorted emotional development and exposure to explicit or harmful content. 

AI companion apps can provide comfort, but from a mental-health standpoint they may create unhealthy dependency, increase loneliness, and negatively affect emotional and social development.

**Sources:**  
-  https://www.adalovelaceinstitute.org/blog/ai-companions/
-  https://www.commonsensemedia.org/sites/default/files/research/report/talk-trust-and-trade-offs_2025_web.pdf
